var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = GBModels","category":"page"},{"location":"#GBModels","page":"Home","title":"GBModels","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for GBModels.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [GBModels]","category":"page"},{"location":"#GBModels.LπDist","page":"Home","title":"GBModels.LπDist","text":"Laplace distribution with a point mass at 0.0\n\n\n\n\n\n","category":"type"},{"location":"#GBModels.NπDist","page":"Home","title":"GBModels.NπDist","text":"Gaussian distribution with a point mass at 0.0\n\n\n\n\n\n","category":"type"},{"location":"#GBModels.TπDist","page":"Home","title":"GBModels.TπDist","text":"T-distribution with a point mass at 0.0\n\n\n\n\n\n","category":"type"},{"location":"#Base.maximum-Tuple{GBModels.LπDist}","page":"Home","title":"Base.maximum","text":"Maximum value of the LπDist distribution\n\n\n\n\n\n","category":"method"},{"location":"#Base.maximum-Tuple{GBModels.NπDist}","page":"Home","title":"Base.maximum","text":"Maximum value of the NπDist distribution\n\n\n\n\n\n","category":"method"},{"location":"#Base.maximum-Tuple{GBModels.TπDist}","page":"Home","title":"Base.maximum","text":"Maximum value of the TπDist distribution\n\n\n\n\n\n","category":"method"},{"location":"#Base.minimum-Tuple{GBModels.LπDist}","page":"Home","title":"Base.minimum","text":"Minimum value of the LπDist distribution\n\n\n\n\n\n","category":"method"},{"location":"#Base.minimum-Tuple{GBModels.NπDist}","page":"Home","title":"Base.minimum","text":"Minimum value of the NπDist distribution\n\n\n\n\n\n","category":"method"},{"location":"#Base.minimum-Tuple{GBModels.TπDist}","page":"Home","title":"Base.minimum","text":"Minimum value of the TπDist distribution\n\n\n\n\n\n","category":"method"},{"location":"#Base.rand-Tuple{Random.AbstractRNG, GBModels.LπDist}","page":"Home","title":"Base.rand","text":"Sampling method for LπDist\n\nExamples\n\nd = LπDist(0.1, 0.0, 1.0)\nrand(d)\n\n\n\n\n\n","category":"method"},{"location":"#Base.rand-Tuple{Random.AbstractRNG, GBModels.NπDist}","page":"Home","title":"Base.rand","text":"Sampling method for NπDist\n\nExamples\n\nd = NπDist(0.1, 0.0, 1.0)\nrand(d)\n\n\n\n\n\n","category":"method"},{"location":"#Base.rand-Tuple{Random.AbstractRNG, GBModels.TπDist}","page":"Home","title":"Base.rand","text":"Sampling method for TπDist\n\nExamples\n\nd = TπDist(0.1, 1.0)\nrand(d)\n\n\n\n\n\n","category":"method"},{"location":"#Distributions.logpdf-Tuple{GBModels.LπDist, Real}","page":"Home","title":"Distributions.logpdf","text":"log(pdf) of LπDist\n\nExamples\n\nd = LπDist(0.1, 0.0, 1.0)\nlogpdf.(d, [-1.0, 0.0, 1.0])\n\n\n\n\n\n","category":"method"},{"location":"#Distributions.logpdf-Tuple{GBModels.NπDist, Real}","page":"Home","title":"Distributions.logpdf","text":"log(pdf) of NπDist\n\nExamples\n\nd = NπDist(0.1, 0.0, 1.0)\nlogpdf.(d, [-1.0, 0.0, 1.0])\n\n\n\n\n\n","category":"method"},{"location":"#Distributions.logpdf-Tuple{GBModels.TπDist, Real}","page":"Home","title":"Distributions.logpdf","text":"log(pdf) of TπDist\n\nExamples\n\nd = TπDist(0.1, 1.0)\nlogpdf.(d, [-1.0, 0.0, 1.0])\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.addnorm-Tuple{Any, Any}","page":"Home","title":"GBModels.addnorm","text":"addnorm(x, y) = (x + y) / 2.0\n\nAn endofunction within the zero to one domain which accepts two inputs, and divides their sum by two.\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.bayesa-Tuple{}","page":"Home","title":"GBModels.bayesa","text":"bayesa(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    idx_trait::Int64 = 1,\n    verbose::Bool = false,\n)::Fit\n\nFit a Bayes A model via BGLR\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fit = bayesa(genomes=genomes, phenomes=phenomes);\n\njulia> fit.model == \"bayesa\"\ntrue\n\njulia> fit.metrics[\"cor\"] > 0.50\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.bayesb-Tuple{}","page":"Home","title":"GBModels.bayesb","text":"bayesb(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    idx_trait::Int64 = 1,\n    verbose::Bool = false,\n)::Fit\n\nFit a Bayes A model via BGLR\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fit = bayesb(genomes=genomes, phenomes=phenomes);\n\njulia> fit.model == \"bayesb\"\ntrue\n\njulia> fit.metrics[\"cor\"] > 0.50\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.bayesc-Tuple{}","page":"Home","title":"GBModels.bayesc","text":"bayesc(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    idx_trait::Int64 = 1,\n    verbose::Bool = false,\n)::Fit\n\nFit a Bayes A model via BGLR\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fit = bayesc(genomes=genomes, phenomes=phenomes);\n\njulia> fit.model == \"bayesc\"\ntrue\n\njulia> fit.metrics[\"cor\"] > 0.50\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.bayesian-Tuple{Function}","page":"Home","title":"GBModels.bayesian","text":"bayesian(\n    turing_model::Function;\n    X::Matrix{Float64},\n    y::Vector{Float64},\n    sampler::String = [\"NUTS\", \"HMC\", \"HMCDA\", \"MH\", \"PG\"][1],\n    sampling_method::Int64 = 1,\n    seed::Int64 = 123,\n    n_burnin::Int64 = 500,\n    n_iter::Int64 = 1_500,\n    verbose::Bool = false,\n)::Fit\n\nFit a Bayesian linear regression models via Turing.jl\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> sol = Suppressor.@suppress bayesian(turing_bayesG, genomes=genomes, phenomes=phenomes);\n\njulia> # Slow because not multivariate T-dist: sol_T = Suppressor.@suppress bayesian(turing_bayesT, genomes=genomes, phenomes=phenomes);\n\njulia> # Even slower because of an extra set of distribution to define a non-spherical variance-covariance matrix: sol_Gs = Suppressor.@suppress bayesian(turing_bayesGs, genomes=genomes, phenomes=phenomes);\n\njulia> sol_BGLR = Suppressor.@suppress bayesian(\"BayesA\", genomes=genomes, phenomes=phenomes); sol.metrics[\"cor\"] > sol_BGLR.metrics[\"cor\"]\ntrue\n\njulia> sol.metrics[\"cor\"] > 0.5\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.bayesian-Tuple{String}","page":"Home","title":"GBModels.bayesian","text":"bayesian(\n    bglr_model::String;\n    X::Matrix{Float64},\n    y::Vector{Float64},\n    n_burnin::Int64 = 500,\n    n_iter::Int64 = 1_500,\n    verbose::Bool = false,\n)::Fit\n\nFit a Bayesian linear regression models via BGLR in R\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> sol = Suppressor.@suppress bayesian(\"BayesA\", genomes=genomes, phenomes=phenomes);\n\njulia> sol.metrics[\"cor\"] > 0.5\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.bglr-Tuple{}","page":"Home","title":"GBModels.bglr","text":"Bayesian models using BGLR, i.e. Bayes A, Bayes B and Bayes C\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.cvbulk-Tuple{}","page":"Home","title":"GBModels.cvbulk","text":"cvbulk(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    models::Vector{Function}=[ridge],\n    n_replications::Int64=5,\n    n_folds::Int64=5,\n    seed::Int64=42,\n    verbose::Bool=true\n)::Tuple{Vector{CV}, Vector{String}}\n\nBulk (regardless of population groupings) replicated cross-validation of genomic prediction model/s across all available traits. \n\nNote that to use multiple threads, please invoke Julia as: julia --threads 7,1 --load test/interactive_prelude.jl, where --threads 7,1 means use 7 threads for multi-threaded processes while reserving 1 thread for the Julia runtime itself.\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> cvs, notes = cvbulk(genomes=genomes, phenomes=phenomes, models=[ols, ridge], n_replications=2, n_folds=2, verbose=false);\n\njulia> df_across_entries, df_per_entry = tabularise(cvs);\n\njulia> idx_across = findall((df_across_entries.trait .== \"trait_1\") .&& (df_across_entries.model .== \"ridge\") .&& (df_across_entries.replication .== \"replication_1\") .&& (df_across_entries.fold .== \"fold_1\"));\n\njulia> idx_per = findall((df_per_entry.trait .== \"trait_1\") .&& (df_per_entry.model .== \"ridge\") .&& (df_per_entry.replication .== \"replication_1\") .&& (df_per_entry.fold .== \"fold_1\"));\n\njulia> abs(df_across_entries.cor[idx_across][1] - cor(df_per_entry.y_true[idx_per], df_per_entry.y_pred[idx_per])) < 1e-10\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.cvleaveonepopulationout-Tuple{}","page":"Home","title":"GBModels.cvleaveonepopulationout","text":"cvleaveonepopulationout(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    models::Vector{Function}=[ridge],\n    n_replications::Int64=5,\n    n_folds::Int64=5,\n    seed::Int64=42,\n    verbose::Bool=true\n)::Tuple{Vector{CV}, Vector{String}}\n\nLeave-one-population-out cross-validation of genomic prediction model/s across all available traits.\n\nNote that to use multiple threads, please invoke Julia as: julia --threads 7,1 --load test/interactive_prelude.jl, where --threads 7,1 means use 7 threads for multi-threaded processes while reserving 1 thread for the Julia runtime itself.\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> cvs, notes = cvleaveonepopulationout(genomes=genomes, phenomes=phenomes, models=[ridge, bayesa], n_replications=2, n_folds=2, verbose=false);\n\njulia> df_across_entries, df_per_entry = tabularise(cvs);\n\njulia> sum([sum(split(df_across_entries.training_population[i], \";\") .== df_across_entries.validation_population[i]) for i in 1:size(df_across_entries, 1)]) == 0\ntrue\n\njulia> idx_across = findall((df_across_entries.validation_population .== \"pop_1\") .&& (df_across_entries.trait .== \"trait_1\") .&& (df_across_entries.model .== \"ridge\"));\n\njulia> idx_per = findall((df_per_entry.validation_population .== \"pop_1\") .&& (df_per_entry.trait .== \"trait_1\") .&& (df_per_entry.model .== \"ridge\"));\n\njulia> abs(df_across_entries.cor[idx_across][1] - cor(df_per_entry.y_true[idx_per], df_per_entry.y_pred[idx_per])) < 1e-10\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.cvmultithread!-Tuple{Vector{GBCore.CV}}","page":"Home","title":"GBModels.cvmultithread!","text":"cvmultithread!(cvs::Vector{CV}; genomes::Genomes, phenomes::Phenomes, models::Vector{Function})\n\nMulti-threded generic genomic prediction cross-validation \n\nNote that to use multiple threads, please invoke Julia as: julia --threads 7,1 --load test/interactive_prelude.jl, where --threads 7,1 means use 7 threads for multi-threaded processes while reserving 1 thread for the Julia runtime itself.\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> idx_training = collect(1:50);\n\njulia> idx_validation_1 = collect(51:75);\n\njulia> idx_validation_2 = collect(76:100);\n\njulia> fit = Fit(n = length(idx_training), l = length(genomes.loci_alleles) + 1); fit.model = \"ridge\"; fit.trait = \"trait_1\"; \n\njulia> fit.entries = genomes.entries[idx_training]; fit.populations = genomes.populations[idx_training]; \n\njulia> fit.b_hat_labels = vcat([\"intercept\"], genomes.loci_alleles);\n\njulia> cv_1 = CV(\"replication_1\", \"fold_1\", fit, genomes.populations[idx_validation_1], genomes.entries[idx_validation_1], zeros(length(idx_validation_1)), zeros(length(idx_validation_1)), fit.metrics);\n\njulia> cv_2 = CV(\"replication_1\", \"fold_2\", fit, genomes.populations[idx_validation_2], genomes.entries[idx_validation_2], zeros(length(idx_validation_2)), zeros(length(idx_validation_2)), fit.metrics);\n\njulia> cvs = [cv_1, cv_2]; models = [ridge, ridge];\n\njulia> cvmultithread!(cvs, genomes=genomes, phenomes=phenomes, models_vector=[ridge, bayesa], verbose=false);\n\njulia> df_across_entries, df_per_entry = tabularise(cvs);\n\njulia> idx_across = findall(df_across_entries.fold .== \"fold_2\");\n\njulia> idx_per = findall(df_per_entry.fold .== \"fold_2\");\n\njulia> abs(df_across_entries.cor[idx_across][1] - cor(df_per_entry.y_true[idx_per], df_per_entry.y_pred[idx_per])) < 1e-10\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.cvpairwisepopulation-Tuple{}","page":"Home","title":"GBModels.cvpairwisepopulation","text":"cvpairwisepopulation(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    models::Vector{Function}=[ridge],\n    n_replications::Int64=5,\n    n_folds::Int64=5,\n    seed::Int64=42,\n    verbose::Bool=true\n)::Tuple{Vector{CV}, Vector{String}}\n\nPairwise population cross-validation of genomic prediction model/s across all available traits.\n\nNote that to use multiple threads, please invoke Julia as: julia --threads 7,1 --load test/interactive_prelude.jl, where --threads 7,1 means use 7 threads for multi-threaded processes while reserving 1 thread for the Julia runtime itself.\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> cvs, notes = cvpairwisepopulation(genomes=genomes, phenomes=phenomes, models=[ols, ridge], n_replications=2, n_folds=2, verbose=false);\n\njulia> df_across_entries, df_per_entry = tabularise(cvs);\n\njulia> sum(df_across_entries.training_population .!= df_across_entries.validation_population) == size(df_across_entries, 1)\ntrue\n\njulia> idx_across = findall((df_across_entries.training_population .== \"pop_1\") .&& (df_across_entries.validation_population .== \"pop_2\") .&& (df_across_entries.trait .== \"trait_1\") .&& (df_across_entries.model .== \"ridge\"));\n\njulia> idx_per = findall((df_per_entry.training_population .== \"pop_1\") .&& (df_per_entry.validation_population .== \"pop_2\") .&& (df_per_entry.trait .== \"trait_1\") .&& (df_per_entry.model .== \"ridge\"));\n\njulia> abs(df_across_entries.cor[idx_across][1] - cor(df_per_entry.y_true[idx_per], df_per_entry.y_pred[idx_per])) < 1e-10\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.cvperpopulation-Tuple{}","page":"Home","title":"GBModels.cvperpopulation","text":"cvperpopulation(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    models::Vector{Function}=[ridge],\n    n_replications::Int64=5,\n    n_folds::Int64=5,\n    seed::Int64=42,\n    verbose::Bool=true\n)::Tuple{Vector{CV}, Vector{String}}\n\nWithin population replicated cross-validation of genomic prediction model/s across all available traits.\n\nNote that to use multiple threads, please invoke Julia as: julia --threads 7,1 --load test/interactive_prelude.jl, where --threads 7,1 means use 7 threads for multi-threaded processes while reserving 1 thread for the Julia runtime itself.\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> cvs, notes = cvperpopulation(genomes=genomes, phenomes=phenomes, models=[ols, ridge], n_replications=2, n_folds=2, verbose=false);\n\njulia> df_across_entries, df_per_entry = tabularise(cvs);\n\njulia> sort(unique(df_across_entries.training_population))\n3-element Vector{String}:\n \"pop_1\"\n \"pop_2\"\n \"pop_3\"\n\njulia> df_across_entries.training_population == df_across_entries.validation_population\ntrue\n\njulia> idx_across = findall((df_across_entries.validation_population .== \"pop_1\") .&& (df_across_entries.trait .== \"trait_1\") .&& (df_across_entries.model .== \"ridge\") .&& (df_across_entries.replication .== \"replication_1\") .&& (df_across_entries.fold .== \"fold_1\"));\n\njulia> idx_per = findall((df_per_entry.validation_population .== \"pop_1\") .&& (df_per_entry.trait .== \"trait_1\") .&& (df_per_entry.model .== \"ridge\") .&& (df_per_entry.replication .== \"replication_1\") .&& (df_per_entry.fold .== \"fold_1\"));\n\njulia> abs(df_across_entries.cor[idx_across][1] - cor(df_per_entry.y_true[idx_per], df_per_entry.y_pred[idx_per])) < 1e-10\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.epistasisfeatures-Tuple{GBCore.Genomes, GBCore.Phenomes}","page":"Home","title":"GBModels.epistasisfeatures","text":"epistasisfeatures(\n    genomes::Genomes,\n    phenomes::Phenomes;\n    idx_trait::Int64 = 1,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    transformations1::Vector{Function} = [square, invoneplus, log10epsdivlog10eps],\n    transformations2::Vector{Function} = [mult, addnorm, raise],\n    n_new_features_per_transformation::Int64 = 1_000,\n    n_reps::Int64 = 3,\n    verbose::Bool = false,\n)::Genomes\n\nGenerate epistasis features.\n\nExample\n\njulia> genomes = GBCore.simulategenomes(l=1_000, verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> genomes_plus_features = epistasisfeatures(genomes, phenomes, n_new_features_per_transformation=50, n_reps=2, verbose=false);\n\njulia> cvs, notes = cvbulk(genomes=genomes_plus_features, phenomes=phenomes, models=[ridge, lasso, bayesa], verbose=false);\n\njulia> cvs_no_epi, notes_no_epi = cvbulk(genomes=genomes, phenomes=phenomes, models=[ridge, lasso, bayesa], verbose=false);\n\njulia> df_across, df_per_entry = GBCore.tabularise(cvs);\n\njulia> df_across_no_epi, df_per_entry_no_epi = GBCore.tabularise(cvs_no_epi);\n\njulia> df_summary = combine(groupby(df_across, [:trait, :model]), [[:cor] => mean, [:cor] => std]);\n\njulia> df_summary_no_epi = combine(groupby(df_across_no_epi, [:trait, :model]), [[:cor] => mean, [:cor] => std]);\n\njulia> mean(df_summary.cor_mean) > mean(df_summary_no_epi.cor_mean)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.extractxyetc-Tuple{GBCore.Genomes, GBCore.Phenomes}","page":"Home","title":"GBModels.extractxyetc","text":"extractxyetc(\n    genomes::Genomes,\n    phenomes::Phenomes;\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    idx_trait::Int64 = 1,\n    add_intercept::Bool = true,\n)::Tuple{Matrix{Float64},Vector{Float64},Vector{String},Vector{String},Vector{String}}\n\nExtract explanatory X matrix, response y vector, names of the entries, populations and loci-alleles from genomes and phenomes.\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> X, y, loci_alleles = extractxyetc(genomes, phenomes);\n\njulia> X == hcat(ones(length(phenomes.entries)), genomes.allele_frequencies)\ntrue\n\njulia> y == phenomes.phenotypes[:, 1]\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.invoneplus-Tuple{Any}","page":"Home","title":"GBModels.invoneplus","text":"invoneplus(x) = sqrt(abs(x))\n\nAn endofunction within the zero to one domain which accepts a single input and takes the inverse of one plus the input.\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.lasso-Tuple{}","page":"Home","title":"GBModels.lasso","text":"lasso(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    idx_trait::Int64 = 1,\n    verbose::Bool = false,\n)::Fit\n\nFit a LASSO (least absolute shrinkage and selection operator; L1) regression model\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fit = lasso(genomes=genomes, phenomes=phenomes);\n\njulia> fit.model == \"lasso\"\ntrue\n\njulia> fit.metrics[\"cor\"] > 0.50\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.log10epsdivlog10eps-Tuple{Any}","page":"Home","title":"GBModels.log10epsdivlog10eps","text":"log10epsdivlog10eps(x)\n\nAn endofunction within the zero to one domain which accepts a single input and take its log10 corrected by machine epsilon to keep it in the domain.\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.mult-Tuple{Any, Any}","page":"Home","title":"GBModels.mult","text":"mult(x, y) = x * y\n\nAn endofunction within the zero to one domain which accepts two inputs and multiplies them.\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.ols-Tuple{}","page":"Home","title":"GBModels.ols","text":"ols(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    idx_trait::Int64 = 1,\n    verbose::Bool = false,\n)::Fit\n\nFit an ordinary least squares model\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fit = ols(genomes=genomes, phenomes=phenomes);\n\njulia> fit.model == \"ols\"\ntrue\n\njulia> fit.metrics[\"cor\"] > 0.50\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.predict-Tuple{}","page":"Home","title":"GBModels.predict","text":"predict(; fit::Fit, genomes::Genomes, idx_entries::Vector{Int64})::Vector{Float64}\n\nPredict the phenotypes given a genomic prediction model fit, a genomes and the corresponding entries indexes\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fit = ridge(genomes=genomes, phenomes=phenomes, idx_entries=collect(1:90));\n\njulia> y_hat = GBModels.predict(fit=fit, genomes=genomes, idx_entries=collect(91:100));\n\njulia> cor(phenomes.phenotypes[91:100, 1], y_hat) > 0.5\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.raise-Tuple{Any, Any}","page":"Home","title":"GBModels.raise","text":"raise(x, y) = x^y\n\nAn endofunction within the zero to one domain which accepts two inputs, and raises the first to the power of the second.\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.reconstitutefeatures-Tuple{GBCore.Genomes}","page":"Home","title":"GBModels.reconstitutefeatures","text":"reconstitutefeatures(genomes::Genomes, feature_names::Vector{String})::Genomes\n\nReconstitute epistasis features given a genomes struct and names of the features which include the endofunction names used.\n\nExample\n\njulia> genomes = GBCore.simulategenomes(l=1_000, verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> genomes_epifeat = epistasisfeatures(genomes, phenomes, n_new_features_per_transformation=50, n_reps=2, verbose=false);\n\njulia> feature_names = genomes_epifeat.loci_alleles;\n\njulia> genomes_epifeat_reconstructed = reconstitutefeatures(genomes, feature_names=feature_names);\n\njulia> genomes_epifeat == genomes_epifeat_reconstructed\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.ridge-Tuple{}","page":"Home","title":"GBModels.ridge","text":"ridge(;\n    genomes::Genomes,\n    phenomes::Phenomes,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    idx_trait::Int64 = 1,\n    verbose::Bool = false,\n)::Fit\n\nFit a ridge (L2) regression model\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fit = ridge(genomes=genomes, phenomes=phenomes);\n\njulia> fit.model == \"ridge\"\ntrue\n\njulia> fit.metrics[\"cor\"] > 0.50\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.square-Tuple{Any}","page":"Home","title":"GBModels.square","text":"square(x) = x^2\n\nAn endofunction within the zero to one domain which accepts a single input and squares it.\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.transform1-Tuple{Function, GBCore.Genomes, GBCore.Phenomes}","page":"Home","title":"GBModels.transform1","text":"transform1(\n    f::Function,\n    genomes::Genomes,\n    phenomes::Phenomes;\n    idx_trait::Int64 = 1,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    n_new_features_per_transformation::Int64 = 1_000,\n    ϵ::Float64 = eps(Float64),\n    use_abs::Bool = false,\n    σ²_threshold::Float64 = 0.01,\n    verbose::Bool = false,\n)::Genomes\n\nApply a function to each allele frequency in genomes. Please Use named functions if you wish to reconstruct the transformation from the loci_alleles field.\n\nExample\n\njulia> genomes = GBCore.simulategenomes(l=1_000, verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> genomes_transformed = transform1(x -> x^2, genomes, phenomes);\n\njulia> idx = findall(genomes.loci_alleles .== split(split(replace(genomes_transformed.loci_alleles[1], \")\" => \"\"), \"(\")[2], \",\")[1])[1];\n\njulia> mean(sqrt.(genomes_transformed.allele_frequencies[:, 1]) .- genomes.allele_frequencies[:, idx]) < 1e-10\ntrue\n\njulia> squareaddpi(x) = x^2 + pi;\n\njulia> genomes_transformed = transform1(squareaddpi, genomes, phenomes);\n\njulia> idx = findall(genomes.loci_alleles .== split(split(replace(genomes_transformed.loci_alleles[1], \")\" => \"\"), \"(\")[2], \",\")[1])[1];\n\njulia> mean(squareaddpi.(genomes.allele_frequencies[:, idx]) .- genomes_transformed.allele_frequencies[:, 1]) < 1e-10\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.transform2-Tuple{Function, GBCore.Genomes, GBCore.Phenomes}","page":"Home","title":"GBModels.transform2","text":"transform2(\n    f::Function,\n    genomes::Genomes,\n    phenomes::Phenomes;\n    idx_trait::Int64 = 1,\n    idx_entries::Union{Nothing,Vector{Int64}} = nothing,\n    idx_loci_alleles::Union{Nothing,Vector{Int64}} = nothing,\n    n_new_features_per_transformation::Int64 = 1_000,\n    ϵ::Float64 = eps(Float64),\n    use_abs::Bool = false,\n    σ²_threshold::Float64 = 0.01,\n    commutative::Bool = false,\n    verbose::Bool = false,\n)::Genomes\n\nApply a function to pairs of allele frequency in genomes. Please Use named functions if you wish to reconstruct the transformation from the loci_alleles field.\n\nExample\n\njulia> genomes = GBCore.simulategenomes(l=1_000, verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);;\n\njulia> phenomes = extractphenomes(trials);\n\njulia> genomes_transformed = transform2((x,y) -> (x^2 + sqrt(y)) / 2, genomes, phenomes);\n\njulia> idx_1 = findall(genomes.loci_alleles .== split(split(replace(genomes_transformed.loci_alleles[1], \")\" => \"\"), \"(\")[2], \",\")[1])[1];\n\njulia> idx_2 = findall(genomes.loci_alleles .== split(split(replace(genomes_transformed.loci_alleles[1], \")\" => \"\"), \"(\")[2], \",\")[2])[1];\n\njulia> mean((genomes.allele_frequencies[:,idx_1].^2 .+ sqrt.(genomes.allele_frequencies[:,idx_2])) ./ 2 .- genomes_transformed.allele_frequencies[:,1]) < 1e-10\ntrue\n\njulia> raisexbyythenlog(x, y) = log(abs(x^y));\n\njulia> genomes_transformed = transform2(raisexbyythenlog, genomes, phenomes);\n\njulia> idx_1 = findall(genomes.loci_alleles .== split(split(replace(genomes_transformed.loci_alleles[1], \")\" => \"\"), \"(\")[2], \",\")[1])[1];\n\njulia> idx_2 = findall(genomes.loci_alleles .== split(split(replace(genomes_transformed.loci_alleles[1], \")\" => \"\"), \"(\")[2], \",\")[2])[1];\n\njulia> mean(raisexbyythenlog.(genomes.allele_frequencies[:,idx_1], genomes.allele_frequencies[:,idx_2]) .- genomes_transformed.allele_frequencies[:,1]) < 1e-10\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesG-Tuple{Any, Any}","page":"Home","title":"GBModels.turing_bayesG","text":"Turing specification of Bayesian linear regression using a Gaussian prior with common variance\n\nExample usage\n\n# Benchmarking\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\nmodel = turing_bayesG(G, y)\nbenchmarks = TuringBenchmarking.benchmark_model(\n    model;\n    # Check correctness of computations\n    check=true,\n    # Automatic differentiation backends to check and benchmark\n    adbackends=[:forwarddiff, :reversediff, :reversediff_compiled, :zygote]\n)\n\n\n# Test more loci\ngenomes = GBCore.simulategenomes(n=10, l=10_000)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Check for uninferred types in the model\n@code_warntype model = turing_bayesG(G, y)\n# Fit\nmodel = turing_bayesG(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.65, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# @time chain = Turing.sample(rng, model, HMC(0.05, 10; adtype=AutoReverseDiff(compile=true)), niter, progress=true);\np = Plots.histogram(chain[:σ²])\nPlots.gui(p)\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[501:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesG_logit-Tuple{Any, Any}","page":"Home","title":"GBModels.turing_bayesG_logit","text":"Turing specification of Bayesian logistic regression using a Gaussian prior with common variance\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesGs-Tuple{Any, Any}","page":"Home","title":"GBModels.turing_bayesGs","text":"Turing specification of Bayesian linear regression using a Gaussian prior with varying variances\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesGs(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesGπ-Tuple{Any, Any}","page":"Home","title":"GBModels.turing_bayesGπ","text":"Turing specification of Bayesian linear regression using a Gaussian prior with a point mass at zero and common variance\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesGπ(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesGπs-Union{Tuple{T}, Tuple{Any, Any}, Tuple{Any, Any, DynamicPPL.TypeWrap{T}}} where T","page":"Home","title":"GBModels.turing_bayesGπs","text":"Turing specification of Bayesian linear regression using a Gaussian prior with a point mass at zero and varying variances\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesGπs(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesL-Tuple{Any, Any}","page":"Home","title":"GBModels.turing_bayesL","text":"Turing specification of Bayesian linear regression using a Laplacian prior with a common scale\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesL(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesLs-Union{Tuple{T}, Tuple{Any, Any}, Tuple{Any, Any, DynamicPPL.TypeWrap{T}}} where T","page":"Home","title":"GBModels.turing_bayesLs","text":"Turing specification of Bayesian linear regression using a Laplacian prior with varying scales\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesLs(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesLπ-Tuple{Any, Any}","page":"Home","title":"GBModels.turing_bayesLπ","text":"Turing specification of Bayesian linear regression using a Laplacian prior with a point mass at zero and common scale\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesLπ(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesLπs-Union{Tuple{T}, Tuple{Any, Any}, Tuple{Any, Any, DynamicPPL.TypeWrap{T}}} where T","page":"Home","title":"GBModels.turing_bayesLπs","text":"Turing specification of Bayesian linear regression using a Laplacian prior with a point mass at zero and common scale\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesLπs(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesT-Tuple{Any, Any}","page":"Home","title":"GBModels.turing_bayesT","text":"Turing specification of Bayesian linear regression using a T-distribution\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesT(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.turing_bayesTπ-Tuple{Any, Any}","page":"Home","title":"GBModels.turing_bayesTπ","text":"Turing specification of Bayesian linear regression using a T-distribution with a point mass at zero\n\nExample usage\n\n# Simulate data\ngenomes = GBCore.simulategenomes(n=10, l=100)\ntrials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.9 0.01 0.00;])\nphenomes = extractphenomes(trials)\n# Extract genotype and phenotype data\nG::Matrix{Float64} = genomes.allele_frequencies\ny::Vector{Float64} = phenomes.phenotypes[:, 1]\n# Regress for just 200 iterations for demonstration purposes only. Use way way more iterations, e.g. 10,000.\nmodel = turing_bayesTπ(G, y)\n# We use compile=true in AutoReverseDiff() because we do not have any if-statements in our Turing model below\nrng::TaskLocalRNG = Random.seed!(123)\nniter::Int64 = 1_500\nnburnin::Int64 = 500\n@time chain = Turing.sample(rng, model, NUTS(nburnin, 0.5, max_depth=5, Δ_max=1000.0, init_ϵ=0.2; adtype=AutoReverseDiff(compile=true)), niter-nburnin, progress=true);\n# Use the mean paramter values after 150 burn-in iterations\nparams = Turing.get_params(chain[150:end, :, :]);\nb_hat = vcat(mean(params.intercept), mean(stack(params.coefficients, dims=1)[:, :, 1], dims=2)[:,1]);\n# Assess prediction accuracy\ny_pred::Vector{Float64} = hcat(ones(size(G,1)), G) * b_hat;\nUnicodePlots.scatterplot(y, y_pred)\nperformance::Dict{String, Float64} = metrics(y, y_pred)\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.validate-Tuple{GBCore.Fit, GBCore.Genomes, GBCore.Phenomes}","page":"Home","title":"GBModels.validate","text":"validate(\n    fit::Fit,\n    genomes::Genomes,\n    phenomes::Phenomes; \n    idx_validation::Vector{Int64},\n    replication::String=\"\",\n    fold::String=\"\"\n)::CV\n\nAssess the accuracy of a genomic prediction model fit on a validation set of entries\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(verbose=false);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, f_add_dom_epi=[0.1 0.01 0.01;], verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fit = ridge(genomes=genomes, phenomes=phenomes, idx_entries=collect(1:90));\n\njulia> cv = validate(fit, genomes, phenomes, idx_validation=collect(91:100));\n\njulia> cv.metrics[\"cor\"] > 0.50\ntrue\n\n\n\n\n\n","category":"method"},{"location":"#GBModels.@string2operations-Tuple{Any}","page":"Home","title":"GBModels.@string2operations","text":"string2operations(x)\n\nMacro to Meta.parse a string of endofunction formulae across allele frequencies.\n\n\n\n\n\n","category":"macro"}]
}
